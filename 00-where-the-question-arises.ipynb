{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified: Aug 31, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where the story starts\n",
    "- We ask questions about variables in the world\n",
    "- What are simple examples of these questions?\n",
    "    - (unconditioned) variable\n",
    "    - variable in the context of other variables: **conditioned** setting\n",
    "- How does probability can be used as a language to express these questions in a principled way, and furthermore to answer these questions\n",
    "\n",
    "- What do we mean by a \"model\"?\n",
    "- What about \"parameters of a model?\" \n",
    "    - Motivation for \"parametrizing\" a model \n",
    "        - aka. restricting the possible \"form\" that your \"model\" can take)\n",
    "        - aka. bringing/choosing some sort of structure to your \"model\"\n",
    "    - Some examples of models and simple model parametrization (again, \"parametrization\" $\\equiv$ \"restricting a possible form that your model can take\". We call this \"restricted set of possible model\", a **family*** of model)\n",
    "\n",
    "## Keywords\n",
    "- (unconditioned) variables\n",
    "    - unsupervised setting\n",
    "- variables in context with other variables: conditioned setting\n",
    "    - supervised setting\n",
    "    - conditional probability\n",
    "- predictive probability\n",
    "    - don't bring a notion of \"time\" here though. It's not about a \"next\"/\"new\"/\"test\" case. It's about the state of your understanding of the variable of interest\n",
    "\n",
    "- model\n",
    "- parametrized model\n",
    "- a family of models\n",
    "\n",
    "- Bayesian point of view \n",
    "    - prior distribution of the parameter (of your model)\n",
    "    - posterior distribution of the parameter\n",
    "    \n",
    "- Learning \n",
    "    - $\\equiv$ choosing a \"good\" parameter for your pararmetrized model\n",
    "- Possible principles to guide your learning process\n",
    "    - Principle of maximizing the likelihood of seeing/generating your observed data given your model: Maximum-Likelihood\n",
    "    - Principle of maximizing the likelihood of seeing/generating your observed data given your model with prior knowledge: Maximum a Posteriori (MAP) - Bayesian approach\n",
    "    - Any other principles ...?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coming up\n",
    "- (unconditioned) variable: aka. standalone variable\n",
    "    - choose a parametrized model (aka. choose a family of model, aka. choose a structure of your model)\n",
    "    - if you take a Bayesian approach, you need to make two choices\n",
    "        - one for the generating process of your variable of interest (here 'unconditioned' variable): $P(X \\vert \\theta)$\n",
    "        - another for the distribution over $\\theta$: $\\theta$\n",
    "        - **Conjugate** priors: a pair of these two model families that makes your life easier\n",
    "            - Beta-Bernoulli model: when your variable of interest is binary (aka. either 0 or 1)\n",
    "            - Dirichlet-Categorical model: when your variable of interest is multi-nominal (aka. its value comes from a set bigger than of size 2)\n",
    "            \n",
    "- Variable in context with other variables \n",
    "    - Simple examples\n",
    "        - Naive Bayes classifier for SPAM VS. HAM\n",
    "        - Slightly extended version of Naive Bayes\n",
    "        - Bayesian Naive Bayes\n",
    "    - Log-linear models\n",
    "        - Conditional Random Field (CRF)\n",
    "        - Examples with text\n",
    "        - Examples with images\n",
    "        - Relation to Logistic Regression\n",
    "        - Relation to Naive Bayes\n",
    "        - Relation to RNN\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a football field. Your coach wants to know what the actual width of the field is. Some people say it's 100 meters, others say 102.5, etc. He hires you to tell him what the actual width is. \n",
    "\n",
    "You - you have a yard stick. You take the job and set out to measure the width of the field. You can measure it once. But being a good statistician, you make multiple measurements. After making these multiple measurements, now you wonder what to give to your coach as the \"true\" width of the field. \n",
    "\n",
    "---\n",
    "Here is another question that may arise in the world.\n",
    "You have students in a lecture hall. You wonder what the SAT score of a student if you grab an arbitrary student and ask for his/her score. So, you first set out by asking many students for their SAT scores:\n",
    "<todo: add a cute diagram>\n",
    "\n",
    "We are going to call these collected measurements, \"data\" or \"observations\" and will denote is by $D$:\n",
    "\n",
    "$D = \\{100, 200, 101, 102, \\dots, 102.3\\}$\n",
    "\n",
    "We will use $X$ to denote the variable of interest (here the SAT score) and call each of the SAT scores you get from asking the students, a \"realization\" of your variable $X$. Each realization (ie. measurement, observed data point) will be indexed by a superscript: $X^{(1)}, X^{(2)}$, etc. With these notations, we express our set of $n$ measurements as:\n",
    "\n",
    "$D = \\{X^{(1)}, X^{(2)}, \\dots, X^{(n)} \\}$\n",
    "\n",
    "Now that you have asked $n$ students for their SAT scores, what is your understanding (ie. \"model\") of the SAT score of students in the lecture hall?\n",
    "\n",
    "Notice you are looking at the SAT score, and the SAT score alone. You don't look at any other variables that may exist in your world. But just the SAT scores. But you may choose to do so.  Here is a scenario that describes this different problem.\n",
    "\n",
    "---\n",
    "Now, you start looking at other variables existing in your world. Although we introduce this scenario **after** the scenario of looking at the SAT score as a standalone variable, this doesn't imply this is a more complicated, or in any way a \"better\" way to ask questions about the variable of your interest (here, the SAT score).\n",
    "\n",
    "For instance, when you grab a student, we kind of enter into the world of this new student. So, this student may be a Female, from Korea, Asian, who graduated from a boarding school, and who has an average HW score of 99.2. When you ask another student, the student is Male, from France but Asian ethnicity, graduated from a public school, and has an average HW score of 85.7. So you want to take these other variables (Gender, Origin of Country, Ethnicity, Type of high school he/she graduated from, and the average HW scores in the class) and given these contextual variables, you want to understand the student's SAT score. It's like, when you grab a student, you enter a universe of this student (exactly specified by the students gender, origin, ethnicity, high school type and avg. HW score), AND understand the SAT score variable within this universe. When you ask a different student, you are now entering a different world/universe that is configured by this new student's gender, origin, ethnicity, high school type and the average HW score) and want to understand the SAT score within this universe.  \n",
    "\n",
    "---\n",
    "to continue: \n",
    "- introduce conditioning\n",
    "- abstract notation of conditioned setting\n",
    "- a chart comparing standalone variable vs. variable within contexts of other variables\n",
    "- unsupervised vs. supervised\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:earthml]",
   "language": "python",
   "name": "conda-env-earthml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
